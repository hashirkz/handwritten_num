{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# reading train and test data and shuffling train data \n",
    "TRAIN = pd.read_csv('./train.csv').to_numpy(dtype='int64')\n",
    "TEST = pd.read_csv('./test.csv').to_numpy(dtype='int64')\n",
    "np.random.shuffle(TRAIN)\n",
    "\n",
    "# these are train/test x y but those are dumb names\n",
    "imgs, labels = TRAIN[:, 1:], TRAIN[:, 0]\n",
    "imgs_test, labels_test = TEST[:, 1:], TEST[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the nth image from either the test or training set\n",
    "# if your using this to view/graph the image pass view=True\n",
    "def read_nth_img(data, n, view=False):\n",
    "\n",
    "    # read training data into image arrays\n",
    "    img = data[n:n+1, 1:].reshape(28, 28) if view else np.transpose(data[n:n+1, 1:])\n",
    "    label = data[n, 0]\n",
    "    \n",
    "    return [img, label]\n",
    "\n",
    "# plot numpy array *img* as grayscale image on matplotlib graph\n",
    "def graph_img(img):\n",
    "    plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "\n",
    "# example call to view a training data image\n",
    "img, label = read_nth_img(TRAIN, 217, view=True)\n",
    "print(f'label: {label}')\n",
    "graph_img(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.4649 - accuracy: 0.8814\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2891 - accuracy: 0.9327\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1822 - accuracy: 0.9496\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1580 - accuracy: 0.9558\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1412 - accuracy: 0.9596\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2017 - accuracy: 0.9515\n",
      "test_data:\n",
      "loss: 0.20169603824615479\n",
      "acc: 0.9514999985694885\n",
      "\n",
      "INFO:tensorflow:Assets written to: handwritten_ml\\assets\n"
     ]
    }
   ],
   "source": [
    "# stochastic gradient descent training for nn\n",
    "# name parameter saves nn as a folder ./name\n",
    "def train_nn(name):\n",
    "\n",
    "    # create a 3 hidden layer nn\n",
    "    # input layer takes 784 row 1 col array of nodes\n",
    "    # nodes have a brightness value 0...255 of its brightness in the image\n",
    "    # 2 hidden layers using relu activation and output layer using softmax to compress values between 0...1\n",
    "    nn = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Input(shape=(784,), name='a0'),\n",
    "            tf.keras.layers.Dense(units=128, activation='relu', name='a1'),\n",
    "            tf.keras.layers.Dense(units=128, activation='relu', name='a2'),\n",
    "            tf.keras.layers.Dense(units=10, activation='softmax', name='a3'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # fit the nn to the training data\n",
    "    nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    nn.fit(imgs, labels, epochs=5)\n",
    "\n",
    "    # test the nn on the test data and see its performance loss and acc\n",
    "    loss, acc = nn.evaluate(imgs_test, labels_test)\n",
    "    print(f'test_data:\\nloss: {loss}\\nacc: {acc}\\n')\n",
    "    nn.save(name)\n",
    "\n",
    "train_nn('handwritten_ml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b79a9603654acc1a1dda7ab9d7fbeea5670a7835087b35cd5f08522a1762abf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
